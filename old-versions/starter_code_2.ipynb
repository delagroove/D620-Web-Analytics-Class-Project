{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Machine Learning Classifers with NLTK\n",
    "\n",
    "## CUNY DATA 620 Web Analytics\n",
    "\n",
    "### Fall 2018 Semester Class Project\n",
    "\n",
    "\n",
    "# Instructions\n",
    "\n",
    "- Using any of the three classifiers described in chapter 6 of Natural Language Processing with Python, and any features you can think of, build the best name gender classifier you can. \n",
    "\n",
    "\n",
    "- Begin by splitting the Names Corpus into three subsets: 500 words for the test set, 500 words for the dev-test set, and the remaining 6900 words for the training set. \n",
    "\n",
    "\n",
    "- Then, starting with the example name gender classifier, make incremental improvements. Use the dev-test set to check your progress. Once you are satisfied with your classifier, check its final performance on the test set. \n",
    "\n",
    "\n",
    "- How does the performance on the test set compare to the performance on the dev-test set? Is this what you'd expect? \n",
    "\n",
    "Source: Natural Language Processing with Python, exercise 6.10.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import repeat\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Data\n",
    "\n",
    "Using the NLTK's `names` corpus, we will be demonstrating how to create and improve supervised classification models. The corpus contains 2 files called `female.txt` and `male.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['female.txt', 'male.txt']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import names\n",
    "names.fileids() # confirm male and female txt files exist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import the male & female names, look at the first 20 entries for each and store them together in a variable called `people`. We will normalize the names by changing them to lowercase letters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aamir', 'aaron', 'abbey', 'abbie', 'abbot', 'abbott', 'abby', 'abdel', 'abdul', 'abdulkarim', 'abdullah', 'abe', 'abel', 'abelard', 'abner', 'abraham', 'abram', 'ace', 'adair', 'adam']\n",
      "['abagael', 'abagail', 'abbe', 'abbey', 'abbi', 'abbie', 'abby', 'abigael', 'abigail', 'abigale', 'abra', 'acacia', 'ada', 'adah', 'adaline', 'adara', 'addie', 'addis', 'adel', 'adela']\n"
     ]
    }
   ],
   "source": [
    "# load male and female  name files from nltk.names; store in people list\n",
    "males, females = [n.lower() for n in names.words('male.txt')], [n.lower() for n in names.words('female.txt')] \n",
    "\n",
    "print([male for male in males[:20]])\n",
    "print([female for female in females[:20]])\n",
    "\n",
    "people = males + females"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 7944 names in total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7944"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_people = len(people)\n",
    "n_people"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's create the variable `gender`, which will contain the gender labels for each of the names. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# make gender list\n",
    "gender = list(repeat('male', len(males))) + list(repeat('female', len(females)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we plot the frequency of the male and female names, we see that there is a class imbalance between the two labels. There are considerably more females than males."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x22f40632128>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gender_counts = pd.Series(gender).value_counts()\n",
    "gender_counts.plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specifically, more than 60% are female. We will want to be cognizant of this class imbalance when we choose the metrics to evaluate the strength of our model. If we simply predicted that every name was female, we would be correct more than 60% of the time. We may also want to consider stratifying the training, development and testing data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x22f41142518>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gender_counts.divide(n_people).plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "\n",
    "Our raw dataset contains only one predictor variable.  This feature indicates the first name of each observed individual in our data.  Unfortunately, the name variable--in its unprocessed form--will not be very useful for building an accurate gender classification model.  A model constructed using first names only will struggle to predict gender for names not explicitly identified in the training data.  Also, our dataset contains a unique collection of first names within each gender class, but has a small number of overlapping names between gender types.  Without additional feature engineering, our models will not be able to make reasonable guesses when encountering gender-neutral names.  \n",
    "\n",
    "The textbook, *Natural Language Processing with Python*, provides a number of helpful suggestions for extracting new features from first names for gender classification purposes:\n",
    "* isolate the first letter of each name\n",
    "* isolate the last letter of each name\n",
    "* isolate the last two letters of each name.\n",
    "\n",
    "We decided to include these features as possible predictors for our models.  These extracted features can reveal common patterns in the prefixes and suffixes of first names that are often associated with a particular gender.  For instance, many female first names end with the letter \"a\".  \n",
    "\n",
    "Building on the text's suggestions, we also extracted the following features:\n",
    "* the first two letters of each name\n",
    "* the first three letters of each name\n",
    "* the last three letters of each name\n",
    "\n",
    "There were a handful of additional features that we thought might be relevant for gender identification:\n",
    "* the number of vowels in each name\n",
    "* The first two non-contiguous letters of each name \n",
    "* The first three non-contiguous letters\n",
    "* The last two non-contiguous letters\n",
    "* the last three non-contiguous letters\n",
    "\n",
    "We also found an [article](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4446333/) from an academic journal that characterizes certain letters as \"round\" and others as \"sharp\".  The authors contend that round letters tend to be associated with female names, while sharp letters are more often associated with male names.  Using this information, we created the following potential features:\n",
    "* the number of round, consonant letters (\"b\",\"m\", \"l\", and \"n\") in each name\n",
    "* the number of sharp, consant letters (\"k\", \"p\", and \"t\") per name\n",
    "* the number of round vowels (\"u\" and \"o\") in each first name.\n",
    "\n",
    "Finally, we found a Wordpress [blog entry](https://debuk.wordpress.com/tag/feminine-suffixes/) that discusses common female suffixes in first names.  These include names ending in ending in \"a\", \"y\", \"ie\", and \"ah\".  We used this information to create a new binary variable that identifies if one of these suffixes is present in a given name.\n",
    "\n",
    "In the script below, we create a function, *gender_features()*, that returns a dictionary of the extracted features described in this section.  The function has multiple arguments:\n",
    "* a first name to use for extracting features\n",
    "* a list of desired features.  This argument can be used to vary the features that are returned by the function \n",
    "\n",
    "  \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# produce features\n",
    "def gender_features(word, *args):\n",
    "    \"\"\"\n",
    "    function returns dictionary of features\n",
    "        word: name to extract features from\n",
    "        args:  one or more strings to specify desired features, including:\n",
    "                'length','first','first2','first3', 'last', 'last2', 'last3',\n",
    "                'every_other2_beg','every_other3_beg', 'every_other2_end', 'every_other3_end',\n",
    "                'vowel_ct', 'round_cons_ct', 'sharp_cons_ct','round_vowel_ct',\n",
    "                trad_female_end'\n",
    "               \n",
    "    \"\"\"\n",
    "    \n",
    "    gf = {}\n",
    "    \n",
    "    # word length\n",
    "    gf['length'] = len(word)\n",
    "   \n",
    "    # first letters\n",
    "    gf['first'] = word[0].lower()\n",
    "    gf['first2'] = word[0:2].lower()\n",
    "    gf['first3'] = word[0:3].lower() if gf['length'] >2  else word[0:2].lower()\n",
    "    \n",
    "    gf['two_letters'] = 'y' if len(word) == 2 else 'n'\n",
    "    \n",
    "    # last letters\n",
    "    gf['last'] = word[-1].lower()\n",
    "    gf['last2'] = word[-2:].lower()\n",
    "    gf['last3'] = word[-3:].lower() if gf['length'] >2  else word[-2:].lower()\n",
    "    \n",
    "    # every other beg\n",
    "    gf['every_other2_beg'] = word[0]+word[2] if gf['length'] > 2 else word[0]\n",
    "    gf['every_other3_beg'] = gf['every_other2_beg']+word[4]  if gf['length'] > 4 else \\\n",
    "    gf['every_other2_beg']\n",
    "    \n",
    "    # every other end\n",
    "    gf['every_other2_end'] = word[-3]+word[-1] if gf['length'] > 2 else word[-1]\n",
    "    gf['every_other3_end'] = word[-5]+gf['every_other2_end']  if gf['length'] > 4 else \\\n",
    "    gf['every_other2_end']\n",
    "    \n",
    "    # count: vowels, rounded consonants, sharp consonants\n",
    "    for letter in word:\n",
    "        # count vowels\n",
    "        if letter in 'aeiou':\n",
    "            gf['vowel_ct'] = gf.get('vowel_ct',0) + 1\n",
    "        # count rounded consonants\n",
    "        if letter in 'bmln':\n",
    "            gf['round_cons_ct'] = gf.get('round_cons_ct',0) + 1\n",
    "        # count sharp consonants\n",
    "        if letter in 'k,p,t':\n",
    "            gf['sharp_cons_ct'] = gf.get('sharp_cons_ct',0) + 1\n",
    "        # count rounded vowels\n",
    "        if letter in 'uo':\n",
    "            gf['round_vowel_ct'] = gf.get('round_vowel_ct',0) + 1\n",
    "            \n",
    "    # traditional feminine ending, 'y' or 'n'\n",
    "    gf['trad_female_end'] = 'y' if gf['last2'] in ['ie','ah'] or \\\n",
    "    gf['last'] in ['a','y'] else 'n'\n",
    "    \n",
    "    ## patterns: double consonant ends in y: Binny, Daffy...\n",
    "    #gf['consonant_y'] = 'y' if bool(re.search(r\"([b-df-hj-np-tv-z])\\1{1,}y$\", word)) else 'n'\n",
    "    \n",
    "    # generate dictionary subset\n",
    "    return(dict((k, gf[k]) for k in args if k in gf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'length': 5,\n",
       " 'first': 'b',\n",
       " 'first2': 'bi',\n",
       " 'first3': 'bin',\n",
       " 'last': 'y',\n",
       " 'last2': 'ny',\n",
       " 'last3': 'nny',\n",
       " 'every_other2_beg': 'Bn',\n",
       " 'every_other3_beg': 'Bny',\n",
       " 'every_other2_end': 'ny',\n",
       " 'every_other3_end': 'Bny',\n",
       " 'vowel_ct': 1,\n",
       " 'round_cons_ct': 2,\n",
       " 'trad_female_end': 'y'}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# specify which features to use\n",
    "myargs = ['length','first','first2','first3', 'last', 'last2', 'last3', \\\n",
    "          'every_other2_beg','every_other3_beg', 'every_other2_end', 'every_other3_end', \\\n",
    "          'vowel_ct', 'round_cons_ct', 'sharp_cons_ct','round_vowel_ct', \\\n",
    "          'trad_female_end']\n",
    "\n",
    "# specify name, and argument list \n",
    "gender_features('Binny', *myargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training, Development & Test Sets\n",
    "\n",
    "Let's partition our names & labels into 3 buckets. We will stratify each bucket in order to maintain our class imbalance and set the random state to 4.\n",
    "\n",
    "- First, let's set aside 500 observations that will not be used in training or development. We will use this test set to evaluate the strength of the model.\n",
    "\n",
    "- Then, let's hold out another 500 observations to use as a development set to do error analysis.\n",
    "\n",
    "- Finally, we will use the remaining 6944 names to train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set aside 500 samples for testing\n",
    "people_dev_train, people_test, gender_dev_train, gender_test = train_test_split(people, \n",
    "                                                                        gender, \n",
    "                                                                        test_size=500, \n",
    "                                                                        stratify=gender, \n",
    "                                                                        random_state=4)\n",
    "\n",
    "# set aside 500 samples for development\n",
    "people_train, people_devtest, gender_train, gender_devtest = train_test_split(people_dev_train, \n",
    "                                                                            gender_dev_train, \n",
    "                                                                            test_size=500, \n",
    "                                                                            stratify=gender_dev_train,\n",
    "                                                                            random_state=4)\n",
    "\n",
    "# list of tuples (name, gender)\n",
    "train_names = list(zip(people_train, gender_train))\n",
    "devtest_names = list(zip(people_devtest, gender_devtest))\n",
    "test_names = list(zip(people_test, gender_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Classification\n",
    "\n",
    "Let's use the naive Bayes (NB) classifier to build our first model. This model derives its \"naiviete\" from its independence asssumption. NB assumes that all features are independent of one another, but features within real-world data often contain dependencies. \n",
    "\n",
    "## NB Round 1\n",
    "\n",
    "Since using too many dependent features can cause the NB model to double count the effect of what is essentially the same feature, let's initiate the model with only a handful of features and try the additive approach. We will use the name length, first character and last character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(names, genders, features):\n",
    "    \"\"\"\n",
    "    function returns list of tuples (name features, gender)\n",
    "        names: list of names to extract features from\n",
    "        genders: list of gender values\n",
    "        features: list of feature functions           \n",
    "    \"\"\"    \n",
    "    return list(zip(map(lambda d: gender_features(d, *features), names), genders))\n",
    "\n",
    "initial_NB_features = ['length', 'last', 'first']\n",
    "\n",
    "train_features  = create_features(people_train, gender_train, initial_NB_features)\n",
    "devtest_features = create_features(people_devtest, gender_devtest, initial_NB_features)\n",
    "test_features = create_features(people_test, gender_test, initial_NB_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy between the training and development sets is decent at .78."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.78\n"
     ]
    }
   ],
   "source": [
    "# train naive bayes classifier \n",
    "nb_classifier = nltk.NaiveBayesClassifier.train(train_features)\n",
    "# classifer accuracy on validation set\n",
    "print(nltk.classify.accuracy(nb_classifier, devtest_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the likelihood ratios of most informative features so far. The last character provides the most information. We should probably try adding more features from the end of the name to see if they improve the model accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                    last = 'a'            female : male   =     34.9 : 1.0\n",
      "                    last = 'k'              male : female =     30.3 : 1.0\n",
      "                    last = 'f'              male : female =     15.3 : 1.0\n",
      "                    last = 'p'              male : female =     11.2 : 1.0\n",
      "                    last = 'v'              male : female =     11.2 : 1.0\n",
      "                    last = 'd'              male : female =     10.1 : 1.0\n",
      "                    last = 'o'              male : female =      8.3 : 1.0\n",
      "                    last = 'm'              male : female =      8.2 : 1.0\n",
      "                    last = 'r'              male : female =      6.8 : 1.0\n",
      "                    last = 'z'              male : female =      6.4 : 1.0\n",
      "                    last = 'b'              male : female =      6.3 : 1.0\n",
      "                    last = 'w'              male : female =      5.1 : 1.0\n",
      "                    last = 'g'              male : female =      4.9 : 1.0\n",
      "                   first = 'w'              male : female =      4.5 : 1.0\n",
      "                    last = 's'              male : female =      4.2 : 1.0\n",
      "                    last = 't'              male : female =      4.0 : 1.0\n",
      "                    last = 'i'            female : male   =      3.7 : 1.0\n",
      "                   first = 'q'              male : female =      3.1 : 1.0\n",
      "                    last = 'u'              male : female =      2.7 : 1.0\n",
      "                  length = 2                male : female =      2.4 : 1.0\n",
      "                   first = 'k'            female : male   =      2.2 : 1.0\n",
      "                    last = 'x'              male : female =      2.1 : 1.0\n",
      "                   first = 'h'              male : female =      2.1 : 1.0\n",
      "                    last = 'n'              male : female =      2.1 : 1.0\n",
      "                  length = 3                male : female =      2.1 : 1.0\n",
      "                   first = 'u'              male : female =      2.0 : 1.0\n",
      "                    last = 'e'            female : male   =      1.8 : 1.0\n",
      "                    last = 'l'              male : female =      1.7 : 1.0\n",
      "                  length = 15               male : female =      1.7 : 1.0\n",
      "                   first = 'x'              male : female =      1.7 : 1.0\n"
     ]
    }
   ],
   "source": [
    "# look at most informative features\n",
    "nb_classifier.show_most_informative_features(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's take a look at some of the model's misclassified names. From looking at the errors, we see that using only the first and last character is too simplistic. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual, guess, name: \n",
      "\n",
      "('male', 'female', 'wye')\n",
      "('male', 'female', 'llewellyn')\n",
      "('male', 'female', 'smith')\n",
      "('male', 'female', 'garry')\n",
      "('male', 'female', 'thadeus')\n",
      "('male', 'female', 'jereme')\n",
      "('male', 'female', 'harvie')\n",
      "('male', 'female', 'grant')\n",
      "('male', 'female', 'gerrit')\n",
      "('male', 'female', 'woodman')\n",
      "('male', 'female', 'owen')\n",
      "('male', 'female', 'roderic')\n",
      "('male', 'female', 'moses')\n",
      "('male', 'female', 'arvin')\n",
      "('male', 'female', 'moishe')\n",
      "('male', 'female', 'georges')\n",
      "('male', 'female', 'redmond')\n",
      "('male', 'female', 'jud')\n",
      "('male', 'female', 'davin')\n",
      "('male', 'female', 'abe')\n",
      "('male', 'female', 'whitaker')\n",
      "('male', 'female', 'sheffy')\n",
      "('male', 'female', 'michale')\n",
      "('male', 'female', 'rufus')\n",
      "('male', 'female', 'bary')\n",
      "('male', 'female', 'paten')\n",
      "('male', 'female', 'jehu')\n",
      "('male', 'female', 'martyn')\n",
      "('male', 'female', 'bartolemo')\n",
      "('male', 'female', 'trace')\n"
     ]
    }
   ],
   "source": [
    "# look at names that were mis-classified\n",
    "errors = []\n",
    "for (name, tag) in devtest_names:\n",
    "    #print(name)\n",
    "    guess = nb_classifier.classify(gender_features(name))\n",
    "    if guess != tag:\n",
    "        errors.append((tag, guess, name))\n",
    "\n",
    "print('actual, guess, name: \\n')\n",
    "for x in errors[:30]:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NB Round 2\n",
    "\n",
    "Since we did some error analysis, let's make sure that we reset our training and development set, so that the model doesn't become biased towards the previous round's idiosyncracies. We will use a different random state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "people_train_v2, people_devtest_v2, gender_train_v2, gender_devtest_v2 = train_test_split(people_dev_train, \n",
    "                                                                            gender_dev_train, \n",
    "                                                                            test_size=500, \n",
    "                                                                            stratify=gender_dev_train,\n",
    "                                                                            random_state=5)\n",
    "\n",
    "# list of tuples (name, gender)\n",
    "train_names_v2 = list(zip(people_train_v2, gender_train_v2))\n",
    "devtest_names_v2 = list(zip(people_devtest_v2, gender_devtest_v2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this 2nd round, let's add some new features from the end characters of the names. We will add the last 2 and the last 3 letters. We will also add the new features to the test set as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_features_v2 = initial_NB_features + ['last2', 'last3']\n",
    "\n",
    "train_features_v2  = create_features(people_train_v2, gender_train_v2, NB_features_v2)\n",
    "devtest_features_v2 = create_features(people_devtest_v2, gender_devtest_v2, NB_features_v2)\n",
    "test_features_v2 = create_features(people_test, gender_test, NB_features_v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's fit the model again using the new features. The accuracy score has improved from .78 to .788."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.788\n"
     ]
    }
   ],
   "source": [
    "# train naive bayes classifier \n",
    "nb_classifier_v2 = nltk.NaiveBayesClassifier.train(train_features_v2)\n",
    "# # classifer accuracy on validation set\n",
    "print(nltk.classify.accuracy(nb_classifier_v2, devtest_features_v2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared to the 1st round features, the `last2` feature adds a lot of information to the model and `last3` as well to a lesser degree. When the last 2 letters are 'na', the name is 94 times more often female than male."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                   last2 = 'na'           female : male   =     94.1 : 1.0\n",
      "                   last2 = 'ia'           female : male   =     38.5 : 1.0\n",
      "                   last2 = 'ld'             male : female =     37.2 : 1.0\n",
      "                   last2 = 'us'             male : female =     35.6 : 1.0\n",
      "                    last = 'a'            female : male   =     33.6 : 1.0\n",
      "                   last2 = 'sa'           female : male   =     32.6 : 1.0\n",
      "                    last = 'k'              male : female =     30.8 : 1.0\n",
      "                   last3 = 'nne'          female : male   =     29.8 : 1.0\n",
      "                   last2 = 'rd'             male : female =     25.3 : 1.0\n",
      "                   last2 = 'do'             male : female =     25.0 : 1.0\n",
      "                   last2 = 'ta'           female : male   =     24.8 : 1.0\n",
      "                   last3 = 'ana'          female : male   =     24.2 : 1.0\n",
      "                   last3 = 'tta'          female : male   =     24.2 : 1.0\n",
      "                   last2 = 'io'             male : female =     23.9 : 1.0\n",
      "                   last2 = 'ra'           female : male   =     22.4 : 1.0\n",
      "                   last3 = 'ard'            male : female =     21.6 : 1.0\n",
      "                   last3 = 'vin'            male : female =     20.2 : 1.0\n",
      "                   last2 = 'rt'             male : female =     19.7 : 1.0\n",
      "                   last2 = 'os'             male : female =     17.2 : 1.0\n",
      "                   last3 = 'ita'          female : male   =     16.1 : 1.0\n",
      "                    last = 'f'              male : female =     15.9 : 1.0\n",
      "                   last3 = 'son'            male : female =     15.3 : 1.0\n",
      "                   last3 = 'old'            male : female =     15.0 : 1.0\n",
      "                   last2 = 'im'             male : female =     15.0 : 1.0\n",
      "                   last3 = 'ria'          female : male   =     14.4 : 1.0\n",
      "                   last3 = 'dra'          female : male   =     12.6 : 1.0\n",
      "                    last = 'p'              male : female =     12.5 : 1.0\n",
      "                   last2 = 'ch'             male : female =     11.7 : 1.0\n",
      "                   last2 = 'ns'             male : female =     11.7 : 1.0\n",
      "                    last = 'v'              male : female =     11.2 : 1.0\n"
     ]
    }
   ],
   "source": [
    "# # look at most informative features\n",
    "nb_classifier_v2.show_most_informative_features(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NB Testing\n",
    "\n",
    "Let's evaluate our model from round #2 against the test set that we have been holding out from our feature selection process. At 0.816, the features and model perform well against this new set of data. The accuracy is actually a little higher than the model's accuracy against the development set. If model's accuracy decreased vis-a-vis the test set, we would be concerned that the model was overfit to our training data, but that does not appear to be the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.816\n"
     ]
    }
   ],
   "source": [
    "print(nltk.classify.accuracy(nb_classifier_v2, test_features_v2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maximum Entropy Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "http://www.nltk.org/howto/corpus.html\n",
    "\n",
    "[Natural Language Processing with Python: Analyzing Text with the Natural Language Toolkit](https://www.amazon.com/Natural-Language-Processing-Python-Analyzing/dp/0596516495/ref=mt_paperback?_encoding=UTF8&me=&qid=)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
